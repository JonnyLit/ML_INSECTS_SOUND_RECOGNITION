/home/zord/anaconda3/bin/python /home/zord/PycharmProjects/SBCM_4_classes/main.py 
2025-09-22 01:14:55.070649: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
features_queen_absent.shape: (70000, 32, 44)
queen_queen_absent.shape: (70000,)
features_queen_present_newly_accepted.shape: (69983, 32, 44)
queen_queen_present_newly_accepted.shape: (69983,)
features_queen_present_original.shape: (69056, 32, 44)
queen_queen_present_original.shape: (69056,)
features_queen_present_rejected.shape: (69553, 32, 44)
queen_queen_present_rejected.shape: (69553,)
Training...
2025-09-22 01:29:48.701481: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
X_train.shape
195014 32
X_train.shape, Y_train.shape, X_test.shape, Y_test.shape
(195014, 32, 44, 1) (195014, 1) (83578, 32, 44, 1) (83578, 1)
le: LabelEncoder()
after LabelEncoder()
X_train.shape, Y_train.shape, X_test.shape, Y_test.shape
(195014, 32, 44, 1) (195014, 1) (83578, 32, 44, 1) (83578, 1)
after Y_train = to_categorical(le.fit_transform(Y_train))
X_train.shape, Y_train.shape, X_test.shape, Y_test.shape
(195014, 32, 44, 1) (195014, 4) (83578, 32, 44, 1) (83578, 1)
before model.evaluate and after Y_test = to_categorical(le.fit_transform(Y_test))
X_train.shape, Y_train.shape, X_test.shape, Y_test.shape
(195014, 32, 44, 1) (195014, 4) (83578, 32, 44, 1) (83578, 4)
/home/zord/anaconda3/lib/python3.11/site-packages/sklearn/preprocessing/_label.py:110: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
/home/zord/anaconda3/lib/python3.11/site-packages/sklearn/preprocessing/_label.py:110: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
2612/2612 [==============================] - 99s 37ms/step - loss: 1.3862 - accuracy: 0.2457 - precision: 0.0000e+00 - recall: 0.0000e+00
after model.evaluate
X_train.shape, Y_train.shape, X_test.shape, Y_test.shape
(195014, 32, 44, 1) (195014, 4) (83578, 32, 44, 1) (83578, 4)
Predicted accuracy:  24.57345277070999
Epoch 1/110
995/995 [==============================] - 631s 628ms/step - loss: 0.7605 - accuracy: 0.6873 - precision: 0.7996 - recall: 0.5622 - val_loss: 1.1789 - val_accuracy: 0.6423 - val_precision: 0.6721 - val_recall: 0.6094 - lr: 5.0000e-04
Epoch 2/110
995/995 [==============================] - 610s 613ms/step - loss: 0.4664 - accuracy: 0.8234 - precision: 0.8649 - recall: 0.7763 - val_loss: 0.9645 - val_accuracy: 0.6624 - val_precision: 0.7000 - val_recall: 0.6150 - lr: 5.0000e-04
Epoch 3/110
995/995 [==============================] - 650s 654ms/step - loss: 0.3921 - accuracy: 0.8523 - precision: 0.8833 - recall: 0.8186 - val_loss: 0.4436 - val_accuracy: 0.8390 - val_precision: 0.8624 - val_recall: 0.8181 - lr: 5.0000e-04
Epoch 4/110
995/995 [==============================] - 655s 658ms/step - loss: 0.3509 - accuracy: 0.8694 - precision: 0.8948 - recall: 0.8427 - val_loss: 0.5656 - val_accuracy: 0.7923 - val_precision: 0.8147 - val_recall: 0.7697 - lr: 5.0000e-04
Epoch 5/110
995/995 [==============================] - 636s 639ms/step - loss: 0.3233 - accuracy: 0.8805 - precision: 0.9023 - recall: 0.8580 - val_loss: 1.8175 - val_accuracy: 0.5909 - val_precision: 0.6052 - val_recall: 0.5688 - lr: 5.0000e-04
Epoch 6/110
995/995 [==============================] - 659s 662ms/step - loss: 0.3001 - accuracy: 0.8895 - precision: 0.9082 - recall: 0.8701 - val_loss: 0.3027 - val_accuracy: 0.8865 - val_precision: 0.9009 - val_recall: 0.8724 - lr: 5.0000e-04
Epoch 7/110
995/995 [==============================] - 669s 672ms/step - loss: 0.2819 - accuracy: 0.8956 - precision: 0.9130 - recall: 0.8782 - val_loss: 0.6664 - val_accuracy: 0.7866 - val_precision: 0.8020 - val_recall: 0.7714 - lr: 5.0000e-04
Epoch 8/110
995/995 [==============================] - 660s 663ms/step - loss: 0.2687 - accuracy: 0.9009 - precision: 0.9171 - recall: 0.8851 - val_loss: 0.3337 - val_accuracy: 0.8795 - val_precision: 0.8926 - val_recall: 0.8673 - lr: 5.0000e-04
Epoch 9/110
995/995 [==============================] - 638s 641ms/step - loss: 0.2545 - accuracy: 0.9069 - precision: 0.9212 - recall: 0.8928 - val_loss: 0.6213 - val_accuracy: 0.8108 - val_precision: 0.8232 - val_recall: 0.7994 - lr: 5.0000e-04
Epoch 10/110
995/995 [==============================] - 652s 656ms/step - loss: 0.2436 - accuracy: 0.9109 - precision: 0.9243 - recall: 0.8976 - val_loss: 0.6570 - val_accuracy: 0.7744 - val_precision: 0.7904 - val_recall: 0.7607 - lr: 5.0000e-04
Epoch 11/110
995/995 [==============================] - ETA: 0s - loss: 0.2341 - accuracy: 0.9151 - precision: 0.9269 - recall: 0.9026
Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
995/995 [==============================] - 661s 664ms/step - loss: 0.2341 - accuracy: 0.9151 - precision: 0.9269 - recall: 0.9026 - val_loss: 0.3664 - val_accuracy: 0.8764 - val_precision: 0.8865 - val_recall: 0.8686 - lr: 5.0000e-04
Epoch 12/110
995/995 [==============================] - 660s 664ms/step - loss: 0.1915 - accuracy: 0.9296 - precision: 0.9391 - recall: 0.9206 - val_loss: 0.4045 - val_accuracy: 0.8659 - val_precision: 0.8739 - val_recall: 0.8597 - lr: 2.5000e-04
Epoch 13/110
995/995 [==============================] - 651s 655ms/step - loss: 0.1800 - accuracy: 0.9345 - precision: 0.9431 - recall: 0.9263 - val_loss: 0.8770 - val_accuracy: 0.7872 - val_precision: 0.7945 - val_recall: 0.7802 - lr: 2.5000e-04
Epoch 14/110
995/995 [==============================] - 659s 662ms/step - loss: 0.1735 - accuracy: 0.9370 - precision: 0.9450 - recall: 0.9293 - val_loss: 0.6129 - val_accuracy: 0.8362 - val_precision: 0.8449 - val_recall: 0.8283 - lr: 2.5000e-04
Epoch 15/110
995/995 [==============================] - 652s 655ms/step - loss: 0.1689 - accuracy: 0.9380 - precision: 0.9457 - recall: 0.9303 - val_loss: 0.8445 - val_accuracy: 0.7979 - val_precision: 0.8049 - val_recall: 0.7919 - lr: 2.5000e-04
Epoch 16/110
995/995 [==============================] - 669s 673ms/step - loss: 0.1626 - accuracy: 0.9409 - precision: 0.9482 - recall: 0.9339 - val_loss: 0.3584 - val_accuracy: 0.8889 - val_precision: 0.8958 - val_recall: 0.8837 - lr: 2.5000e-04
Epoch 17/110
995/995 [==============================] - 638s 642ms/step - loss: 0.1591 - accuracy: 0.9423 - precision: 0.9492 - recall: 0.9354 - val_loss: 1.4109 - val_accuracy: 0.7229 - val_precision: 0.7301 - val_recall: 0.7160 - lr: 2.5000e-04
Epoch 18/110
995/995 [==============================] - 664s 668ms/step - loss: 0.1531 - accuracy: 0.9442 - precision: 0.9510 - recall: 0.9381 - val_loss: 0.2927 - val_accuracy: 0.9057 - val_precision: 0.9124 - val_recall: 0.9005 - lr: 2.5000e-04
Epoch 19/110
995/995 [==============================] - 666s 669ms/step - loss: 0.1493 - accuracy: 0.9455 - precision: 0.9518 - recall: 0.9394 - val_loss: 0.3726 - val_accuracy: 0.8795 - val_precision: 0.8874 - val_recall: 0.8730 - lr: 2.5000e-04
Epoch 20/110
995/995 [==============================] - 661s 665ms/step - loss: 0.1460 - accuracy: 0.9467 - precision: 0.9529 - recall: 0.9411 - val_loss: 0.2851 - val_accuracy: 0.9067 - val_precision: 0.9127 - val_recall: 0.9025 - lr: 2.5000e-04
Epoch 21/110
995/995 [==============================] - 660s 664ms/step - loss: 0.1410 - accuracy: 0.9484 - precision: 0.9539 - recall: 0.9428 - val_loss: 0.2561 - val_accuracy: 0.9186 - val_precision: 0.9249 - val_recall: 0.9135 - lr: 2.5000e-04
Epoch 22/110
995/995 [==============================] - 633s 636ms/step - loss: 0.1383 - accuracy: 0.9499 - precision: 0.9551 - recall: 0.9447 - val_loss: 0.2554 - val_accuracy: 0.9170 - val_precision: 0.9236 - val_recall: 0.9121 - lr: 2.5000e-04
Epoch 23/110
995/995 [==============================] - 665s 668ms/step - loss: 0.1348 - accuracy: 0.9504 - precision: 0.9557 - recall: 0.9454 - val_loss: 1.0657 - val_accuracy: 0.7778 - val_precision: 0.7833 - val_recall: 0.7727 - lr: 2.5000e-04
Epoch 24/110
995/995 [==============================] - 662s 666ms/step - loss: 0.1309 - accuracy: 0.9522 - precision: 0.9571 - recall: 0.9476 - val_loss: 0.2927 - val_accuracy: 0.9097 - val_precision: 0.9153 - val_recall: 0.9053 - lr: 2.5000e-04
Epoch 25/110
995/995 [==============================] - 629s 633ms/step - loss: 0.1282 - accuracy: 0.9529 - precision: 0.9577 - recall: 0.9481 - val_loss: 0.5774 - val_accuracy: 0.8408 - val_precision: 0.8478 - val_recall: 0.8350 - lr: 2.5000e-04
Epoch 26/110
995/995 [==============================] - ETA: 0s - loss: 0.1232 - accuracy: 0.9548 - precision: 0.9595 - recall: 0.9505
Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.
995/995 [==============================] - 630s 634ms/step - loss: 0.1232 - accuracy: 0.9548 - precision: 0.9595 - recall: 0.9505 - val_loss: 0.3038 - val_accuracy: 0.9067 - val_precision: 0.9124 - val_recall: 0.9018 - lr: 2.5000e-04
Epoch 27/110
995/995 [==============================] - 637s 641ms/step - loss: 0.0981 - accuracy: 0.9643 - precision: 0.9674 - recall: 0.9610 - val_loss: 0.3179 - val_accuracy: 0.9095 - val_precision: 0.9130 - val_recall: 0.9067 - lr: 1.2500e-04
Epoch 28/110
995/995 [==============================] - 657s 660ms/step - loss: 0.0924 - accuracy: 0.9665 - precision: 0.9694 - recall: 0.9639 - val_loss: 0.2726 - val_accuracy: 0.9240 - val_precision: 0.9280 - val_recall: 0.9212 - lr: 1.2500e-04
Epoch 29/110
995/995 [==============================] - 665s 669ms/step - loss: 0.0885 - accuracy: 0.9671 - precision: 0.9702 - recall: 0.9647 - val_loss: 0.3819 - val_accuracy: 0.9035 - val_precision: 0.9067 - val_recall: 0.9014 - lr: 1.2500e-04
Epoch 30/110
995/995 [==============================] - 657s 661ms/step - loss: 0.0855 - accuracy: 0.9685 - precision: 0.9712 - recall: 0.9660 - val_loss: 0.3880 - val_accuracy: 0.9024 - val_precision: 0.9060 - val_recall: 0.8998 - lr: 1.2500e-04
Epoch 31/110
995/995 [==============================] - 621s 625ms/step - loss: 0.0847 - accuracy: 0.9684 - precision: 0.9709 - recall: 0.9661 - val_loss: 0.3312 - val_accuracy: 0.9133 - val_precision: 0.9166 - val_recall: 0.9112 - lr: 1.2500e-04
Epoch 32/110
995/995 [==============================] - 617s 621ms/step - loss: 0.0819 - accuracy: 0.9700 - precision: 0.9723 - recall: 0.9677 - val_loss: 0.4235 - val_accuracy: 0.8979 - val_precision: 0.9006 - val_recall: 0.8959 - lr: 1.2500e-04
Epoch 33/110
995/995 [==============================] - 623s 626ms/step - loss: 0.0803 - accuracy: 0.9708 - precision: 0.9731 - recall: 0.9688 - val_loss: 0.2827 - val_accuracy: 0.9272 - val_precision: 0.9296 - val_recall: 0.9254 - lr: 1.2500e-04
Epoch 34/110
995/995 [==============================] - 661s 665ms/step - loss: 0.0762 - accuracy: 0.9717 - precision: 0.9738 - recall: 0.9697 - val_loss: 0.2944 - val_accuracy: 0.9247 - val_precision: 0.9275 - val_recall: 0.9228 - lr: 1.2500e-04
Epoch 35/110
995/995 [==============================] - 645s 649ms/step - loss: 0.0761 - accuracy: 0.9723 - precision: 0.9741 - recall: 0.9705 - val_loss: 0.5387 - val_accuracy: 0.8838 - val_precision: 0.8861 - val_recall: 0.8822 - lr: 1.2500e-04
Epoch 36/110
995/995 [==============================] - 667s 670ms/step - loss: 0.0736 - accuracy: 0.9728 - precision: 0.9747 - recall: 0.9711 - val_loss: 0.7467 - val_accuracy: 0.8556 - val_precision: 0.8582 - val_recall: 0.8539 - lr: 1.2500e-04
Epoch 37/110
995/995 [==============================] - 661s 664ms/step - loss: 0.0709 - accuracy: 0.9740 - precision: 0.9758 - recall: 0.9724 - val_loss: 0.4767 - val_accuracy: 0.8945 - val_precision: 0.8972 - val_recall: 0.8927 - lr: 1.2500e-04
Epoch 38/110
995/995 [==============================] - ETA: 0s - loss: 0.0693 - accuracy: 0.9745 - precision: 0.9762 - recall: 0.9730
Epoch 38: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.
995/995 [==============================] - 655s 659ms/step - loss: 0.0693 - accuracy: 0.9745 - precision: 0.9762 - recall: 0.9730 - val_loss: 0.3114 - val_accuracy: 0.9262 - val_precision: 0.9283 - val_recall: 0.9245 - lr: 1.2500e-04
Epoch 39/110
995/995 [==============================] - 591s 594ms/step - loss: 0.0546 - accuracy: 0.9803 - precision: 0.9815 - recall: 0.9792 - val_loss: 0.3659 - val_accuracy: 0.9201 - val_precision: 0.9222 - val_recall: 0.9190 - lr: 6.2500e-05
Epoch 40/110
995/995 [==============================] - 616s 619ms/step - loss: 0.0522 - accuracy: 0.9809 - precision: 0.9819 - recall: 0.9800 - val_loss: 0.3118 - val_accuracy: 0.9298 - val_precision: 0.9314 - val_recall: 0.9288 - lr: 6.2500e-05
Epoch 41/110
995/995 [==============================] - 579s 582ms/step - loss: 0.0509 - accuracy: 0.9814 - precision: 0.9826 - recall: 0.9804 - val_loss: 0.4612 - val_accuracy: 0.9059 - val_precision: 0.9075 - val_recall: 0.9048 - lr: 6.2500e-05
Epoch 42/110
995/995 [==============================] - 623s 627ms/step - loss: 0.0488 - accuracy: 0.9819 - precision: 0.9829 - recall: 0.9809 - val_loss: 0.4757 - val_accuracy: 0.9056 - val_precision: 0.9073 - val_recall: 0.9046 - lr: 6.2500e-05
Epoch 43/110
995/995 [==============================] - 617s 620ms/step - loss: 0.0481 - accuracy: 0.9822 - precision: 0.9833 - recall: 0.9815 - val_loss: 0.4524 - val_accuracy: 0.9126 - val_precision: 0.9142 - val_recall: 0.9116 - lr: 6.2500e-05
Epoch 44/110
995/995 [==============================] - 613s 617ms/step - loss: 0.0470 - accuracy: 0.9831 - precision: 0.9840 - recall: 0.9823 - val_loss: 0.3417 - val_accuracy: 0.9286 - val_precision: 0.9302 - val_recall: 0.9276 - lr: 6.2500e-05
Epoch 45/110
995/995 [==============================] - ETA: 0s - loss: 0.0451 - accuracy: 0.9835 - precision: 0.9844 - recall: 0.9827
Epoch 45: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.
995/995 [==============================] - 588s 592ms/step - loss: 0.0451 - accuracy: 0.9835 - precision: 0.9844 - recall: 0.9827 - val_loss: 0.3514 - val_accuracy: 0.9285 - val_precision: 0.9299 - val_recall: 0.9276 - lr: 6.2500e-05
Epoch 46/110
995/995 [==============================] - 542s 544ms/step - loss: 0.0392 - accuracy: 0.9856 - precision: 0.9863 - recall: 0.9850 - val_loss: 0.4822 - val_accuracy: 0.9103 - val_precision: 0.9117 - val_recall: 0.9094 - lr: 3.1250e-05
Epoch 47/110
995/995 [==============================] - 595s 598ms/step - loss: 0.0366 - accuracy: 0.9869 - precision: 0.9876 - recall: 0.9863 - val_loss: 0.3947 - val_accuracy: 0.9266 - val_precision: 0.9278 - val_recall: 0.9259 - lr: 3.1250e-05
Epoch 48/110
995/995 [==============================] - 588s 591ms/step - loss: 0.0359 - accuracy: 0.9869 - precision: 0.9875 - recall: 0.9864 - val_loss: 0.4622 - val_accuracy: 0.9174 - val_precision: 0.9186 - val_recall: 0.9168 - lr: 3.1250e-05
Epoch 49/110
995/995 [==============================] - 557s 560ms/step - loss: 0.0348 - accuracy: 0.9874 - precision: 0.9880 - recall: 0.9869 - val_loss: 0.4548 - val_accuracy: 0.9190 - val_precision: 0.9201 - val_recall: 0.9184 - lr: 3.1250e-05
Epoch 50/110
995/995 [==============================] - ETA: 0s - loss: 0.0344 - accuracy: 0.9877 - precision: 0.9882 - recall: 0.9872
Epoch 50: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.
995/995 [==============================] - 580s 583ms/step - loss: 0.0344 - accuracy: 0.9877 - precision: 0.9882 - recall: 0.9872 - val_loss: 0.5395 - val_accuracy: 0.9077 - val_precision: 0.9088 - val_recall: 0.9069 - lr: 3.1250e-05
195014/195014 [==============================] - 785s 4ms/step - loss: 0.3118 - accuracy: 0.9298 - precision: 0.9314 - recall: 0.9288
WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 195014 batches). You may need to use the repeat() function when building your dataset.
Validation Loss: 0.3118, Validation Accuracy: 0.9298, Validation Precision: 0.9314, Validation Recall: 0.9288
2025-09-22 10:35:26.258205: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,32]
	 [[{{node inputs}}]]
2025-09-22 10:35:26.362976: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,64]
	 [[{{node inputs}}]]
2025-09-22 10:35:26.468028: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,128]
	 [[{{node inputs}}]]
2025-09-22 10:35:26.523199: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,32]
	 [[{{node inputs}}]]
2025-09-22 10:35:28.329924: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,32]
	 [[{{node inputs}}]]
2025-09-22 10:35:28.747162: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,64]
	 [[{{node inputs}}]]
2025-09-22 10:35:29.165010: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,128]
	 [[{{node inputs}}]]
2025-09-22 10:35:29.362989: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,32]
	 [[{{node inputs}}]]
WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 20). These functions will not be directly callable after loading.
2025-09-22 10:35:38.152444: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.
2025-09-22 10:35:38.152498: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.
2025-09-22 10:35:38.154207: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /tmp/tmpnpne5f5o
2025-09-22 10:35:38.179491: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }
2025-09-22 10:35:38.179515: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: /tmp/tmpnpne5f5o
2025-09-22 10:35:38.191753: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
2025-09-22 10:35:38.247869: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:353] MLIR V1 optimization pass is not enabled
2025-09-22 10:35:38.261327: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.
2025-09-22 10:35:38.679822: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /tmp/tmpnpne5f5o
2025-09-22 10:35:38.791673: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 637481 microseconds.
2025-09-22 10:35:39.121540: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
Input details: [{'name': 'serving_default_input_1:0', 'index': 0, 'shape': array([ 1, 32, 44,  1], dtype=int32), 'shape_signature': array([-1, 32, 44,  1], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]
Output details: [{'name': 'StatefulPartitionedCall:0', 'index': 159, 'shape': array([1, 4], dtype=int32), 'shape_signature': array([-1,  4], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]
Training completed in time:  9:03:26.053733
INFO: Created TensorFlow Lite XNNPACK delegate for CPU.
6095/6095 [==============================] - 185s 30ms/step - loss: 0.0333 - accuracy: 0.9873 - precision: 0.9881 - recall: 0.9866
Training Accuracy:  0.9873188734054565
2612/2612 [==============================] - 80s 31ms/step - loss: 0.3118 - accuracy: 0.9298 - precision: 0.9314 - recall: 0.9288
Testing Accuracy:  0.9297901391983032
2612/2612 [==============================] - 76s 29ms/step
1
0
Confusion matrix, without normalization
[[19499   359   647   495]
 [  475 19605   206   709]
 [  777   239 19277   424]
 [  539   579   419 19329]]
qt.qpa.xcb: QXcbConnection: XCB error: 3 (BadWindow), sequence: 1338, resource id: 11309576, major code: 40 (TranslateCoords), minor code: 0
qt.xkb.compose: failed to create compose table

Classification report for MfCCs + CNN for fold1:
                               precision    recall  f1-score   support

                queen_absent       0.92      0.93      0.92     21000
queen_present_newly_accepted       0.94      0.93      0.94     20995
      queen_present_original       0.94      0.93      0.93     20717
      queen_present_rejected       0.92      0.93      0.92     20866

                    accuracy                           0.93     83578
                   macro avg       0.93      0.93      0.93     83578
                weighted avg       0.93      0.93      0.93     83578

rounded_predictions: [0 1 0 ... 3 3 3]
rounded_labels: [0 0 0 ... 3 3 3]
Confusion matrix, without normalization
[[19499   359   647   495]
 [  475 19605   206   709]
 [  777   239 19277   424]
 [  539   579   419 19329]]

Classification report:
                               precision    recall  f1-score   support

                queen_absent       0.92      0.93      0.92     21000
queen_present_newly_accepted       0.94      0.93      0.94     20995
      queen_present_original       0.94      0.93      0.93     20717
      queen_present_rejected       0.92      0.93      0.92     20866

                    accuracy                           0.93     83578
                   macro avg       0.93      0.93      0.93     83578
                weighted avg       0.93      0.93      0.93     83578

Accuracy:  0.9297901361602335
              precision    recall  f1-score      support
0              0.915876  0.928524  0.922157  21000.00000
1              0.943364  0.933794  0.938555  20995.00000
2              0.938099  0.930492  0.934280  20717.00000
3              0.922317  0.926339  0.924324  20866.00000
accuracy       0.929790  0.929790  0.929790      0.92979
macro avg      0.929914  0.929787  0.929829  83578.00000
weighted avg   0.929898  0.929790  0.929822  83578.00000

Process finished with exit code 0
